## Overview

This repository contains two Jupyter notebooks that form a progressive agentic AI system for deep research assistance. These agents utilize local LLMs served through Ollama and enhanced with LangChain, along with external web search and YouTube video analysis. The goal of these agents is to support deep research by retrieving, analyzing, and summarizing content from multiple sources, including web pages and video transcripts.

## Files in This Repository

### task1.ipynb

This notebook implements the **basic local Deep Research Assistant**.

What this agent does:
- Accepts a user-provided research topic.
- Uses a local DeepSeek LLM served via Ollama to generate an initial **search query**.
- Executes a **web search** using DuckDuckGo via LangChain’s DuckDuckGoSearchAPIWrapper.
- Fetches snippets from the top 5 search results.
- Summarizes those snippets using DeepSeek.
- Optionally refines the search process by having the LLM **reflect** on gaps in the initial summary and generate follow-up search queries.
- Combines new web snippets into the summary if refinement occurs.
- Prints the final summary and sources at the end.

Logic Model in task1:
- User provides a topic.
- LLM generates a web search query.
- DuckDuckGo search provides web snippets.
- Snippets are summarized into a coherent research summary.
- The agent reflects on gaps and iteratively performs new searches if necessary.
- The process follows a simplified ReAct (Reasoning + Action) loop, using LangChain’s tool abstraction for search and LLM summarization.
- Outputs include a printed final summary and source list.

### task2youtube.ipynb

This notebook enhances the previous agent by adding **YouTube video search and transcript analysis**, as well as an **email delivery system for the final report**.

What this agent does:
- Accepts a user-provided research topic.
- Generates the initial web search query using the same DeepSeek-Ollama setup.
- Performs both a **DuckDuckGo search** and a **YouTube search** for the same query.
- Retrieves **web snippets** and **YouTube transcripts** from top matching videos.
- Summarizes both web content and video transcripts into a comprehensive initial summary.
- Enters a **refinement loop** where the LLM identifies missing information, generates new search queries, and retrieves new content from both web and YouTube.
- Refines the summary based on new content, iterating up to 3 times.
- Cleans the summary by removing any unwanted reasoning tags like `<think>` to produce a final clean output.
- The final summary and full source list are emailed to the user using **SMTP2GO API**, ensuring easy delivery without needing Gmail app passwords.

Logic Model in task2youtube:
- User provides a topic.
- Initial search query generated by DeepSeek.
- Web and YouTube searches executed in parallel.
- Both web snippets and YouTube transcripts summarized into a combined output.
- Refinement loop triggers if the summary is incomplete, with new queries generated and both web + YouTube re-queried.
- Final summary cleaned to remove reasoning traces, thinking tags, and process reflections.
- Final summary and source list are emailed via SMTP2GO, using the official email API for reliable delivery.
- Prints the final summary and sources to the console as well for backup visibility.

## Requirements

To run these notebooks successfully, the following dependencies and configurations are required:

- Python 3.10+
- Jupyter Notebook or JupyterLab
- ollama (running locally) with DeepSeek model pulled:
    ```
    ollama pull deepseek-chat
    ```
- Packages (install via pip):
    ```
    langchain
    langchain_community
    langchain_ollama
    duckduckgo-search
    youtube-search-python==1.6.5
    youtube-transcript-api
    requests
    smtplib (part of standard library)
    email (part of standard library)
    python-dotenv (optional for loading credentials from a .env file)
    ```
- SMTP2GO Account if using the email functionality (with verified sender or smtp2go.net sender)

## Installation

1. Clone this repository to your machine.
2. Set up and run Ollama:
    ```
    ollama serve
    ollama pull deepseek-chat
    ```
3. Install Python dependencies:
    ```
    pip install -r requirements.txt
    ```
    If you want to include the requirements file, it would look like:
    ```
    langchain
    langchain_community
    langchain_ollama
    duckduckgo-search
    youtube-search-python==1.6.5
    youtube-transcript-api
    requests
    python-dotenv
    ```
4. Create a free SMTP2GO account if you want to send email reports.
5. In **task2youtube.ipynb**, update the email-sending section to include your real:
    - SMTP2GO API Key
    - Verified sender email address

## How to Run

1. Open the notebooks in Jupyter.
2. Run **task1.ipynb** if you only want basic web-based research.
3. Run **task2youtube.ipynb** if you want:
    - Web + YouTube research
    - Email delivery of the final report
4. Follow prompts to enter your research topic and email (for task 2).

## Example Output (Summary and Sources)

A typical console output at the end looks like this:
```
=== Final Report Sent ===
Topic: Impact of Urban Heat Islands on Public Health

Final Research Summary:
Urban heat islands increase heat stress, especially in vulnerable populations such as older adults and low-income communities. 
Green infrastructure, including tree planting and cool roofs, is effective in mitigating UHI effects. Climate justice concerns arise 
because UHI effects are more severe in historically marginalized neighborhoods.

Sources:
https://www.epa.gov/heatislands
https://www.sciencedirect.com/science/article/pii/S0013935122000023
https://www.youtube.com/watch?v=abc12345678
```

## Notes on LLM Usage

- The **deepseek-r1:1.5b** model is used in both agents.
- This model runs locally via Ollama, so no API costs apply.
- LangChain handles all interaction with the LLM, including query generation, summarization, reflection, and refinement.
- DeepSeek is explicitly prompted to **avoid chain-of-thought explanations** in this version, though earlier versions allowed thinking-style responses.

## Limitations

- The accuracy and depth of summaries depend heavily on the **quality of initial search results and transcripts**.
- Current YouTube transcript fetching works only for videos with captions enabled.
- Web search via DuckDuckGo may occasionally return unrelated results if the LLM generates vague or over-broad queries.
- Running Ollama locally requires sufficient CPU or GPU, and initial `ollama pull` may take some time.
- Email delivery relies on external infrastructure (SMTP2GO), which can have occasional rate limits or delays.

## Future Enhancements

- Add automatic language detection for non-English topics.
- Allow user to specify preferred sources (e.g., academic papers only).
- Automatically generate citations in APA/MLA/Chicago style.
- Add a front-end (Streamlit or Gradio) for non-technical users.

